#### CF Template 1
## Parameters - User Input
Parameters:
  DeploymentName:
    Description: This is the name of the deployment
    Type: String
    MinLength: 1

  S3BucketDeployedByVodSolution:
    Description: Enter the bucket name of the S3 bucket created by the VOD on AWS solution, alternatively, enter another bucket in the same account. This bucket will host the Lambda function files (the size requirement is very small)
    Type: String

  S3PolicyForMediaAccess:
    Description: Policy that gives Lambda access to customer managed S3 Bucket
    Type: String
    AllowedPattern: ^arn:aws:iam::.+ #(\d{12}|aws):policy/:+
    Default: arn:aws:iam::aws:policy/AmazonS3ReadOnlyAccess

  CloudFrontDistributionDomainName:
    Description: Enter the base name of the CloudFront distribution that will be used
    Type: String
    Default: mydistribution.net

## Resources
Resources:
#
# DynamoDB
# Tables: 00000_Clients (client_id (String)) 00000_ContentLibrary (assetname (String)) 00000_ContentManagement (endtimeepoch (Number))
  ClientDB:
    Type: AWS::DynamoDB::Table
    Properties:
      TableName: 00002_Clients
      BillingMode: PAY_PER_REQUEST
      KeySchema:
        - AttributeName: client_id
          KeyType: HASH
      AttributeDefinitions:
        - AttributeName: client_id
          AttributeType: S

  ContentLibraryDB:
    Type: AWS::DynamoDB::Table
    Properties:
      TableName: 00002_ContentLibrary
      BillingMode: PAY_PER_REQUEST
      KeySchema:
        - AttributeName: assetname
          KeyType: HASH
      AttributeDefinitions:
        - AttributeName: assetname
          AttributeType: S

  ContentManagementDB:
    Type: AWS::DynamoDB::Table
    Properties:
      TableName: 00002_ContentManagement
      BillingMode: PAY_PER_REQUEST
      KeySchema:
        - AttributeName: endtimeepoch
          KeyType: HASH
      AttributeDefinitions:
        - AttributeName: endtimeepoch
          AttributeType: N

#
# IAM
# Lambda Role (S3 Access) // API Gateway invoke access
  LambdaRole:
    Type: AWS::IAM::Role
    Properties:
      ManagedPolicyArns:
        - !Sub ${S3PolicyForMediaAccess}
      AssumeRolePolicyDocument:
        Version: 2012-10-17
        Statement:
          - Effect: Allow
            Principal:
              Service:
                - lambda.amazonaws.com
            Action:
              - sts:AssumeRole
      Tags:
        - Key: StackName
          Value: !Ref AWS::StackName

    ## IAM Policy
  CustomPoliciesForLambda:
    Type: AWS::IAM::Policy
    Properties:
      Roles:
        - !Ref LambdaRole
      PolicyName: !Sub ${AWS::StackName}-s3-access
      PolicyDocument:
        Statement:
          - Effect: Allow
            Action:
              - s3:*
            Resource:
              - !Sub arn:aws:s3:::${S3BucketDeployedByVodSolution}/*
          - Effect: Allow
            Action:
              - s3:*
            Resource:
              - !Sub arn:aws:s3:::${S3BucketDeployedByVodSolution}
          - Effect: Allow
            Action:
              - logs:CreateLogGroup
              - logs:CreateLogStream
              - logs:PutLogEvents
            Resource:
              - !Sub arn:aws:logs:${AWS::Region}:${AWS::AccountId}:*
          - Effect: Allow
            Action:
              - dynamodb:*
            Resource:
              - !Sub arn:aws:dynamodb:${AWS::Region}:${AWS::AccountId}:table/*_Clients
              - !Sub arn:aws:dynamodb:${AWS::Region}:${AWS::AccountId}:table/*_ContentLibrary
              - !Sub arn:aws:dynamodb:${AWS::Region}:${AWS::AccountId}:table/*_ContentManagement
              # replace above with :
              #  !GetAtt ClientDB.Arn
              #  !GetAtt ContentLibraryDB.Arn
              #  !GetAtt ContentManagementDB.Arn

  #LambdaInvokePermissionAPIGateway:
  #  Type: AWS::Lambda::Permission
  #  Properties:
  #    FunctionName: !GetAtt VodLinearizer.Arn
  #    Action: lambda:InvokeFunction
  #    Principal: apigateway.amazonaws.com
  #    SourceArn: !Sub "arn:aws:execute-api:${AWS::Region}:${AWS::AccountId}:${ApiGateway}/*/*/*"
  #  DependsOn:
  #    - VodLinearizer

#################
## Custom Resource
#################
  FileMover:
    Type: Custom::LambdaInvokerToMoveFiles
    Properties:
      ServiceToken: !GetAtt FileCopier.Arn
      Region: !Ref 'AWS::Region'

#
# Lambda
#
## Content Ingest to DB
## Linearizer // vod content ingest // file loaders

  VodLinearizer:
    Type: AWS::Lambda::Function
    Properties:
      Description: Function that creates a linear playlist from VOD playlist sources
      Role: !GetAtt LambdaRole.Arn
      Runtime: python3.8
      Handler: index.lambda_handler
      Timeout: 10
      MemorySize: 10240
      Environment:
        Variables:
          SLIDING_WINDOW: 30
          CDN: !Ref CloudFrontDistributionDomainName
      Code:
        S3Bucket: !Ref S3BucketDeployedByVodSolution
        S3Key: !GetAtt FileMover.hls_vod_linearizer
      Tags:
        - Key: StackName
          Value: !Ref AWS::StackName
    DependsOn:
      - LambdaRole
      - FileCopier
      - FileMover


  VodContentIngest: # Adapt lambda for MediaConvert trigger. get tags also
    Type: AWS::Lambda::Function
    Properties:
      Description: Function that parses the HLS manifest to calculate Asset length and other details
      Role: !GetAtt LambdaRole.Arn
      Runtime: python3.8
      Handler: index.lambda_handler
      Timeout: 10
      MemorySize: 10240
      Code:
        S3Bucket: !Ref S3BucketDeployedByVodSolution
        S3Key: !GetAtt FileMover.vod-content-ingest
      Environment:
        Variables:
          CONTENT_MANAGEMENT_DB: !Ref ContentManagementDB
          CONTENT_LIBRARY_DB: !Ref ContentLibraryDB
      Tags:
        - Key: StackName
          Value: !Ref AWS::StackName
    DependsOn:
      - LambdaRole
      - FileCopier
      - FileMover

  FileCopier:
    Type: AWS::Lambda::Function
    Properties:
      FunctionName: !Sub ${AWS::StackName}-functioncopiertos3
      Description: Lambda function to copy solution files to target bucket
      Role: !GetAtt LambdaRole.Arn
      Runtime: python3.8
      Handler: index.lambda_handler
      Timeout: 30
      MemorySize: 10240
      Code:
        ZipFile: |
          '''
          Copyright (c) 2021 Scott Cunningham

          Permission is hereby granted, free of charge, to any person obtaining a copy
          of this software and associated documentation files (the "Software"), to deal
          in the Software without restriction, including without limitation the rights
          to use, copy, modify, merge, publish, distribute, sublicense, and/or sell
          copies of the Software, and to permit persons to whom the Software is
          furnished to do so, subject to the following conditions:

          The above copyright notice and this permission notice shall be included in all
          copies or substantial portions of the Software.

          THE SOFTWARE IS PROVIDED "AS IS", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR
          IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY,
          FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE
          AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER
          LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM,
          OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE
          SOFTWARE.

          Summary: This script is a custom resource to place the HTML pages and Lambda code into the destination bucket.

          Original Author: Scott Cunningham
          '''

          import json
          import logging
          import boto3
          import os
          import urllib3
          from urllib.parse import urlparse
          from zipfile import ZipFile
          import cfnresponse

          LOGGER = logging.getLogger()
          LOGGER.setLevel(logging.INFO)
          MANIFESTMODIFY="True"

          def lambda_handler(event, context):

            ## Log the incoming event
            LOGGER.info("Event : %s " % (event))

            ## Create Response Data Dictionary for the CloudFormationn response
            responseData = dict()

            ## Initialize S3 boto3 client
            s3 = boto3.client('s3')

            # Create urllib3 pool manager
            http = urllib3.PoolManager()

            # environment variables
            bucket = os.environ['BUCKET']
            apiendpoint = os.environ['APIENDPOINT']

            # Manifest File containning URL's on github
            cloudformation_manifest = "https://raw.githubusercontent.com/scunning1987/hls_vod_linearizer/main/manifest.txt"

            # Get the manifest from GitHub
            try:
              get_response = http.request('GET', cloudformation_manifest)
            except:
              responseData['Status'] = "HTTP call to get manifest failed"
              cfnresponse.send(event, context, "FAILED",responseData)
              raise Exception("HTTP call to get manifest failed")

            if get_response.status != 200:
                # Exit the script with errors
                responseData['Status'] = "Unable to get file from location : %s " % (cloudformation_manifest)
                cfnresponse.send(event, context, "FAILED",responseData)
                raise Exception("Unable to get file from location : %s " % (cloudformation_manifest))
            else:
                # Continue and upload to S3
                manifest_list = get_response.data.decode("utf-8").split("\n")

            # remove manifest.txt header line
            manifest_list.pop(0)

            LOGGER.info("Files to transfer to S3: %s " % (manifest_list))

            for file in manifest_list:

                # Get the file from GitHub
                if "http" in file:
                  try:
                    get_response = http.request('GET', file)
                  except:
                    responseData['Status'] = "HTTP call to get file failed"
                    cfnresponse.send(event, context, "FAILED",responseData)
                    raise Exception("HTTP call to get file failed")

                if get_response.status != 200:
                    # Exit the script with errors
                    responseData['Status'] = "Unable to get file from location : %s " % (file)
                    cfnresponse.send(event, context, "FAILED",responseData)
                    raise Exception("Unable to get file from location : %s " % (file))
                elif "http" in file:

                    # Continue and upload to S3

                    # url string to urllib object
                    file_url_formatted = urlparse(file)
                    file_url_path = file_url_formatted.path

                    # get path after github repo owner name - use this as the path to write to s3
                    path = '/'.join(file_url_path.split("/")[2:]).rsplit("/",1)[0]
                    s3_data = get_response.data


                    file_name = file.rsplit("/",1)[1]
                    file_base_name = os.path.splitext(file_name)[0]
                    s3_key = "%s/%s" % (path,file_name)

                    content_type = ""
                    if ".html" in file_name:
                        content_type = "text/html"
                    elif ".css" in file_name:
                        content_type = "text/css"
                    elif ".js" in file_name:
                        content_type = "text/javascript"
                    elif ".json" in file_name:
                        content_type = "application/json"
                    elif ".zip" in file_name: # this is the zip
                        content_type = "application/zip"
                        s3_key = path + file_name
                    elif ".py" in file_name:
                        # write python file to zip,
                        python_file = open("/tmp/"+file_name,"w")
                        python_file.write(get_response.data.decode("utf-8"))
                        python_file.close()

                        # Zip the file
                        LOGGER.info("Zipping the file : %s " % ("/tmp/"+file_name))
                        zipObj = ZipFile('/tmp/'+file_name.replace(".py",".zip"), 'w')
                        # Add file to the zip
                        zipObj.write('/tmp/'+file_name,"index.py")
                        # close the Zip File
                        zipObj.close()
                        LOGGER.info("Finished zipping file")

                        content_type = "application/zip"
                        s3_data = open("/tmp/"+file_name.replace(".py",".zip"), 'rb')
                        s3_key = s3_key.replace(".py",".zip")

                    # "RequestType": "Create"
                    if event['RequestType'] == "Create" or event['RequestType'] == "Update":
                        # Upload to S3
                        LOGGER.info("Now uploading %s to S3, Bucket: %s , path: %s" % (file_name,bucket,s3_key))
                        try:
                            s3_response = s3.put_object(Body=s3_data, Bucket=bucket, Key=s3_key,ContentType=content_type, CacheControl='no-cache')
                            LOGGER.info("Uploaded %s to S3, got response : %s " % (file_name,s3_response) )
                            responseData[file_base_name] = s3_key
                        except Exception as e:
                            LOGGER.error("Unable to upload %s to S3, got exception: %s" % (file_name,e))
                            responseData['Status'] = "Unable to upload %s to S3, got exception: %s" % (file_name,e)
                            cfnresponse.send(event, context, "FAILED",responseData)
                            raise Exception("Unable to upload %s to S3, got exception: %s" % (file_name,e))

                    else: # DELETE
                        try:
                            s3_response = s3.delete_object(Bucket=bucket,Key=s3_key)
                            LOGGER.info("Deleted %s from S3, got response : %s " % (file_name,s3_response) )
                        except Exception as e:
                            LOGGER.error("Unable to delete %s from S3, got exception: %s" % (file_name,e))
                            responseData['Status'] = "Unable to delete %s from S3, got exception: %s" % (file_name,e)
                            cfnresponse.send(event, context, "FAILED",responseData)
                else:
                    LOGGER.info("Got line in manifest.txt that isn't a URL: %s " % (file))
            responseData['Status'] = "SUCCESS"
            cfnresponse.send(event, context, "SUCCESS",responseData)
            return responseData

      Environment:
        Variables:
          BUCKET: !Ref S3BucketDeployedByVodSolution
          APIENDPOINT: ""
      Tags:
        - Key: StackName
          Value: !Ref AWS::StackName
    DependsOn:
      - LambdaRole
      - CustomPoliciesForLambda


#
# API Gateway
#
## Proxy API Endpoint



#
# EventBridge
#
## Events for EMC job completion (that follow a certain TAG)

  MediaConvertCompletionEvent:
    Type: AWS::Events::Rule
    Properties:
      Description: This event pattern will isolate MediaConvert transcodes designated for the enterprise linear to vod workflow
      EventPattern: {
        "source": [
            "aws.mediaconvert"
        ],
        "detail-type": [
            "MediaConvert Job State Change"
        ],
        "detail": {
          "status": [
              "COMPLETE"
          ],
          "userMetadata": {
            "Workflow": [
                "VodLinearizer"
            ]
          }
        }
      }
      Name: !Sub ${AWS::StackName}-VodLinearizerWorkflow
      Targets:
        - Id: !Sub ${AWS::StackName}-VodContentIngestLambda
          Arn: !GetAtt VodContentIngest.Arn

#################################
# Outputs
#################################

Outputs:
  Test:
    Description: test
    Value: test
